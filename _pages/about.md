---
permalink: /
title: "Ruifan Li (李睿凡)-Homepage"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

李睿凡，博士，现北京邮电大学人工智能学院副教授、博士生导师。主要研究兴趣机器智能和深度学习基础理论与方法及其在多模态计算和自然语言处理等领域的应用。在包括AAAI、ACL、ACM MM、COLING、ECAI、EMNLP、ICME、IJCAI等国际会议及IEEE T-MM、IEEE T-NNLS、TOMM、NEUNET等国际期刊发表学术论文，授权国家发明专利18项。

Publications
======
&#9679;  <span style="font-size: 0.7em; color: white; background-color: #03228d; font-weight: bold; font-style: italic;"> &nbsp;ACM MM 2024 </span> &nbsp;[Triple Alignment Strategies for Zero-shot Phrase Grounding under Weak Supervision](链接), Pengyue Lin, __Ruifan Li\*__, Yuzhe Ji, Zhihan Yu, Fangxiang Feng, Zhanyu Ma, and Xiaojie Wang    
&#9679;  <span style="font-size: 0.7em; color: white; background-color: #03228d; font-weight: bold; font-style: italic;"> &nbsp;ACM MM 2024 </span> &nbsp;[DiffHarmony++: Enhancing Image Harmonization with Harmony-VAE and Inverse Harmonization Model](链接), Pengfei Zhou, Fangxiang Feng, Guang Liu, __Ruifan Li__, and Xiaojie Wang    
&#9679;  <span style="font-size: 0.7em; color: white; background-color: #03228d; font-weight: bold; font-style: italic;"> &nbsp;ICIC 2024 </span> &nbsp;[An Inverse Retrieval Method Via Query Generation for Xiaohongshu’s Search Engine, International Conference on Intelligent Computing](链接), Yuantao Fan, Xinyu Tu, and __Ruifan Li\*__    
&#9679;  <span style="font-size: 0.7em; color: white; background-color: #03228d; font-weight: bold; font-style: italic;"> &nbsp;CVPR 2024 </span> &nbsp;[Revisiting Counterfactual Problems in Referring Expression Comprehension](https://openaccess.thecvf.com/CVPR2024?day=all), Zhihan Yu, and __Ruifan Li\*__    
&#9679;  <span style="font-size: 0.7em; color: white; background-color: #03228d; font-weight: bold; font-style: italic;"> &nbsp;TNNLS 2024 </span> &nbsp;[DualGCN: Exploring Syntactic and Semantic Information for Aspect-based Sentiment Analysis](https://ieeexplore.ieee.org/document/9947346), __Ruifan Li__, Hao Chen, Fangxiang Feng, Zhanyu Ma, Xiaojie Wang, and Eduard H. Hovy    
&#9679;  <span style="font-size: 0.7em; color: white; background-color: #03228d; font-weight: bold; font-style: italic;"> &nbsp;ICASSP 2024 </span> &nbsp;[Visual Prompt Tuning for Weakly Supervised Phrase Grounding](https://ieeexplore.ieee.org/document/10445738), Pengyue Lin, Zhihan Yu, Mingcong Lu, Fangxiang Feng, __Ruifan Li\*__, and Xiaojie Wang    
&#9679;  <span style="font-size: 0.7em; color: white; background-color: #03228d; font-weight: bold; font-style: italic;"> &nbsp;TCSVT 2024 </span> &nbsp;[LGR-NET: Language Guided Reasoning Network for Referring Expression Comprehension](https://ieeexplore.ieee.org/document/10463072), Mingcong Lu, __Ruifan Li\*__, Fangxiang Feng, Zhanyu Ma and Xiaojie Wang    
&#9679;  <span style="font-size: 0.7em; color: white; background-color: #03228d; font-weight: bold; font-style: italic;"> &nbsp;NLPCC 2024 </span> &nbsp;[Enhanced Prompt Learning for Few-shot Text Classification Method](https://xbna.pku.edu.cn/EN/10.13209/j.0479-8023.2023.071), __Ruifan Li\*__, Zhiyu Wei, Yuantao Fan, Shuqin Ye, and Guangwei Zhang    
&#9679;  <span style="font-size: 0.7em; color: white; background-color: #03228d; font-weight: bold; font-style: italic;"> &nbsp;ICONIP 2023 </span> &nbsp;[Knowledge Prompting with Contrastive Learning for Unsupervised CommonsenseQA](https://link.springer.com/chapter/10.1007/978-981-99-8145-8_3), Lihui Zhang and __Ruifan Li\*__    
&#9679;  <span style="font-size: 0.7em; color: white; background-color: #03228d; font-weight: bold; font-style: italic;"> &nbsp;ECAI 2023 </span> &nbsp;[Enhanced Machine Reading Comprehension Method for Aspect Sentiment Quadruplet Extraction](https://ebooks.iospress.nl/volumearticle/64532), Shuqin Ye, Zepeng Zhai, and __Ruifan Li\*__      
&#9679;  <span style="font-size: 0.7em; color: white; background-color: #03228d; font-weight: bold; font-style: italic;"> &nbsp;Electronics 2023 </span> &nbsp;[A Visually Enhanced Neural Encoder for Synset Induction](https://www.mdpi.com/2079-9292/12/16/3521), Guang Chen, Fangxiang Feng, Guangwei Zhang, Xiaoxu Li, and __Ruifan Li\*__       
&#9679;  <span style="font-size: 0.7em; color: white; background-color: #03228d; font-weight: bold; font-style: italic;"> &nbsp;ACL 2023 </span> &nbsp;[USSA: A Unified Table Filling Scheme for Structured Sentiment Analysis](https://aclanthology.org/2023.acl-long.802/), Zepeng Zhai, Hao Chen, __Ruifan Li\*__, and Xiaojie Wang     
&#9679;  <span style="font-size: 0.7em; color: white; background-color: #03228d; font-weight: bold; font-style: italic;"> &nbsp;ACL Findings 2022 </span> &nbsp;[KE-GCL: Knowledge Enhanced Graph Contrastive Learning for Commonsense Question Answering](https://aclanthology.org/2022.findings-emnlp.6/), Lihui Zhang and __Ruifan Li\*__    
&#9679;  <span style="font-size: 0.7em; color: white; background-color: #03228d; font-weight: bold; font-style: italic;"> &nbsp;EMNLP 2022 </span> &nbsp;[COM-MRC: A COntext-Masked Machine Reading Comprehension Framework for Aspect Sentiment Triplet Extraction](https://aclanthology.org/2022.emnlp-main.212/), Zepeng Zhai, Hao Chen, Fangxiang Feng, __Ruifan Li\*__, and Xiaojie Wang    
&#9679;  <span style="font-size: 0.7em; color: white; background-color: #03228d; font-weight: bold; font-style: italic;"> &nbsp;APSIPA ASC 2022 </span> &nbsp;[Semantics-Guided Knowledge Integration for Domain Adaptation Few-shot Relation Extraction](https://ieeexplore.ieee.org/document/9979971), Zeyuan Wang, Yifan Du, Guangwei Zhang, __Ruifan Li\*__, Yongping Xiong and Chuang Zhang    
&#9679;  <span style="font-size: 0.7em; color: white; background-color: #03228d; font-weight: bold; font-style: italic;"> &nbsp;COLING 2022 </span> &nbsp;[A Simple Model for Distantly Supervised Relation Extraction](https://aclanthology.org/2022.coling-1.234/), Ziqin Rao, Fangxiang Feng, __Ruifan Li\*__, and Xiaojie Wang    
&#9679;  <span style="font-size: 0.7em; color: white; background-color: #03228d; font-weight: bold; font-style: italic;"> &nbsp;ICME 2022 </span> &nbsp;[Improving Image Paragraph Captioning with Dual Relations](https://ieeexplore.ieee.org/document/9859701), Yun Liu, Yihui Shi, Fangxiang Feng, __Ruifan Li\*__, Zhanyu Ma, and Xiaojie Wang    
&#9679;  <span style="font-size: 0.7em; color: white; background-color: #03228d; font-weight: bold; font-style: italic;"> &nbsp;TMM 2022 </span> &nbsp;[Modality Disentangled Discriminator for Text-to-Image Synthesis](https://ieeexplore.ieee.org/document/9417738), Fangxiang Feng, Tianrui Niu, __Ruifan Li__, and Xiaojie Wang    
&#9679;  <span style="font-size: 0.7em; color: white; background-color: #03228d; font-weight: bold; font-style: italic;"> &nbsp;ACL 2022 </span> &nbsp;[Enhanced Multi-Channel Graph Convolutional Network for Aspect Sentiment Triplet Extraction](https://aclanthology.org/2022.acl-long.212/), Hao Chen, Zepeng Zhai, Fangxiang Feng, __Ruifan Li__, and Xiaojie Wang    
&#9679;  <span style="font-size: 0.7em; color: white; background-color: #03228d; font-weight: bold; font-style: italic;"> &nbsp;MM Asia 2021 </span> &nbsp;[S2TD: A Tree-Structured Decoder for Image Paragraph Captioning](https://dl.acm.org/doi/10.1145/3469877.3490585), Yihui Shi, Yun Liu, Fangxiang Feng, __Ruifan Li\*__, Zhanyu Ma, and Xiaojie Wang    
&#9679;  <span style="font-size: 0.7em; color: white; background-color: #03228d; font-weight: bold; font-style: italic;"> &nbsp;APSIPA ASC 2021 </span> &nbsp;[Entailment Method Based on Template Selection for Chinese Text Few-shot Learning](https://ieeexplore.ieee.org/document/9689473), Zeyuan Wang, Zhiyu Wei, Lihui Zhang, __Ruifan Li\*__, and Zhanyu Ma    
&#9679;  <span style="font-size: 0.7em; color: white; background-color: #03228d; font-weight: bold; font-style: italic;"> &nbsp;APSIPA ASC 2021 </span> &nbsp;[Image Captioning Based on An Improved Transformer with IoU Position Encoding](https://ieeexplore.ieee.org/document/9689357), Yazhou Li, Yihui Shi, Yun Liu, __Ruifan Li\*__, and Zhanyu Ma    
&#9679;  <span style="font-size: 0.7em; color: white; background-color: #03228d; font-weight: bold; font-style: italic;"> &nbsp;IJCNLP 2021 </span> &nbsp;[Dual Graph Convolutional Neural Networks for Aspect-based Sentiment Analysis](https://aclanthology.org/2021.acl-long.494/), __Ruifan Li__, Hao Chen, Fangxiang Feng, Zhanyu Ma, Xiaojie Wang, and Eduard H. Hovy        
&#9679;  <span style="font-size: 0.7em; color: white; background-color: #03228d; font-weight: bold; font-style: italic;"> &nbsp;TMM 2020 </span> &nbsp;[Exploring Global and Local Linguistic Representations for Text-to-image Synthesis](https://ieeexplore.ieee.org/document/8989803), __Ruifan Li__, Ning Wang, Fangxiang Feng, Guangwei Zhang, and Xiaojie Wang    
&#9679;  <span style="font-size: 0.7em; color: white; background-color: #03228d; font-weight: bold; font-style: italic;"> &nbsp;ACM MM 2020 </span> &nbsp;[Learning Visual Features from Product Title for Image Retrieval](https://dl.acm.org/doi/10.1145/3394171.3416296), Fangxiang Feng, Tianrui Niu, __Ruifan Li__, Xiaojie Wang, and Huixing Jiang    
&#9679;  <span style="font-size: 0.7em; color: white; background-color: #03228d; font-weight: bold; font-style: italic;"> &nbsp;NEUCOM 2020 </span> &nbsp;[Dual-CNN: A Convolutional Language Decoder for Paragraph Image Captioning](https://www.sciencedirect.com/science/article/abs/pii/S0925231220302319), __Ruifan Li__, Haoyu Liang, Yihui Shi, Fangxiang Feng, and Xiaojie Wang    
&#9679;  <span style="font-size: 0.7em; color: white; background-color: #03228d; font-weight: bold; font-style: italic;"> &nbsp;NEUCOM 2020 </span> &nbsp;[Multi-negative samples with Generative Adversarial Networks for image retrieval](https://www.sciencedirect.com/science/article/abs/pii/S0925231219308823), __Ruifan Li__, Xuesen Zhang, Guang Chen, Yuzhao Mao, and Xiaojie Wang    
&#9679;  <span style="font-size: 0.7em; color: white; background-color: #03228d; font-weight: bold; font-style: italic;"> &nbsp;AAAI 2019 </span> &nbsp;[Differential Networks for Visual Question Answering](链接), Chenfei Wu, Jinlai Liu, Xiaojie Wang, and __Ruifan Li__    
&#9679;  <span style="font-size: 0.7em; color: white; background-color: #03228d; font-weight: bold; font-style: italic;"> &nbsp;Cluster Computing 2019 </span> &nbsp;[Retrieving real world clothing images via multi-weight deep convolutional neural networks](https://link.springer.com/article/10.1007/s10586-017-1052-8), __Ruifan Li__, Fangxiang Feng, Ibrar Ahmad, and Xiaojie Wang    
&#9679;  <span style="font-size: 0.7em; color: white; background-color: #03228d; font-weight: bold; font-style: italic;"> &nbsp;IJCAI 2018 </span> &nbsp;[Show and Tell More: Topic-Oriented Multi-Sentence Image Captioning](https://www.ijcai.org/proceedings/2018/592), Yuzhao Mao, Chang Zhou, Xiaojie Wang, and __Ruifan Li__    
&#9679;  <span style="font-size: 0.7em; color: white; background-color: #03228d; font-weight: bold; font-style: italic;"> &nbsp;IEEE Access 2018 </span> &nbsp;[Multiple Features With Extreme Learning Machines For Clothing Image Recognition](https://ieeexplore.ieee.org/document/8388198), __Ruifan Li__, Wencong Lu, Haoyu Liang, Yuzhao Mao, and Xiaojie Wang    
&#9679;  <span style="font-size: 0.7em; color: white; background-color: #03228d; font-weight: bold; font-style: italic;"> &nbsp;China Communications 2017 </span> &nbsp;[Fog computing architecture-based data acquisition for WSN applications](https://ieeexplore.ieee.org/document/8233652), Guangwei Zhang and __Ruifan Li\*__    
&#9679;  <span style="font-size: 0.7em; color: white; background-color: #03228d; font-weight: bold; font-style: italic;"> &nbsp;IEEE Access 2017 </span> &nbsp;[Line and Ligature Segmentation of Urdu Nastaleeq Text](https://ieeexplore.ieee.org/document/7932054), Ibrar Ahmad, Xiaojie Wang, and __Ruifan Li__, Manzoor Ahmed, Rahat Ullah    
&#9679;  <span style="font-size: 0.7em; color: white; background-color: #03228d; font-weight: bold; font-style: italic;"> &nbsp;China Communications 2017 </span> &nbsp;[Offline Urdu Nastaleeq optical character recognition based on stacked denoising autoencoder](https://ieeexplore.ieee.org/document/7839765), Ibrar Ahmad, Xiaojie Wang, __Ruifan Li__ and Shahid Rasheed    
&#9679;  <span style="font-size: 0.7em; color: white; background-color: #03228d; font-weight: bold; font-style: italic;"> &nbsp;TOMM 2015 </span> &nbsp;[Correspondence Autoencoders for Cross-Modal Retrieval](https://dl.acm.org/doi/10.1145/2808205), Fangxiang Feng, Xiaojie Wang, __Ruifan Li__, and Ibrar Ahmad    
&#9679;  <span style="font-size: 0.7em; color: white; background-color: #03228d; font-weight: bold; font-style: italic;"> &nbsp;NEUNET 2015 </span> &nbsp;[Challenges in representation learning: A report on three machine learning contests](https://www.sciencedirect.com/science/article/abs/pii/S0893608014002159), Ian J. Goodfellow, Dumitru Erhan, Pierre Luc Carrier, Aaron C. Courville, Mehdi Mirza, Benjamin Hamner, William Cukierski, Yichuan Tang, David Thaler, Dong-Hyun Lee, Yingbo Zhou, Chetan Ramaiah, Fangxiang Feng, __Ruifan Li__, Xiaojie Wang, Dimitris Athanasakis, John Shawe-Taylor, Maxim Milakov, John Park, Radu Tudor Ionescu, Marius Popescu, Cristian Grozea, James Bergstra, Jingjing Xie, Lukasz Romaszko, Bing Xu, Zhang Chuang, and Yoshua Bengio    
&#9679;  <span style="font-size: 0.7em; color: white; background-color: #03228d; font-weight: bold; font-style: italic;"> &nbsp;NEUCOM 2015 </span> &nbsp;[Deep correspondence restricted Boltzmann machine for cross-modal retrieval](https://dl.acm.org/doi/10.1145/2808205), Fangxiang Feng, __Ruifan Li__, Xiaojie Wang    
&#9679;  <span style="font-size: 0.7em; color: white; background-color: #03228d; font-weight: bold; font-style: italic;"> &nbsp;ACM MM 2014 </span> &nbsp;[Cross-modal Retrieval with Correspondence Autoencoder](https://dl.acm.org/doi/10.1145/2647868.2654902), Fangxiang Feng, Xiaojie Wang, and __Ruifan Li__    



Students
======
近年学生培养情况    

1. 北京邮电大学优秀硕士学位论文（2023年，Zepeng Zhai；2022年，Hao Chen）    
2. 研究生国家奖学金（2022年，Zepeng Zhai；2021年，Hao Chen）    
3. 北京邮电大学优秀学士学位论文（2020年，Lihui Zhang）    


近年研究生去向：阿里、快手、腾讯、网易、字节、中科院自动化所、华为诺亚方舟实验室、微软亚洲工程院、360搜索、中兴通讯、奇安信、京东方、中国农业银行、中金公司、富国基金、世坤咨询等  
  
![访客统计](https://s01.flagcounter.com/count2/6KPu/bg_FFFFFF/txt_000000/border_CCCCCC/columns_2/maxflags_10/viewers_0/labels_0/pageviews_0/flags_0/percent_0/ "访客统计")
